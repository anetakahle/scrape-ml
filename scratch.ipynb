{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "sqlite3.sqlite_version\n",
    "%matplotlib inline\n",
    "\n",
    "database = sqlite3.connect('outdb.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df_benchmarks = pd.read_sql_query(\"SELECT * from Benchmarks\", database)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    id                           name   \n0    1                       Vimeo90K  \\\n1    2  MSU Video Frame Interpolation   \n2    3                         UCF101   \n3    4                     X4K1000FPS   \n4    5                     Middlebury   \n5    6            Vid4 - 4x upscaling   \n6    7                SNU-FILM (easy)   \n7    8              SNU-FILM (medium)   \n8    9                SNU-FILM (hard)   \n9   10             SNU-FILM (extreme)   \n10  11                  X4K1000FPS-2K   \n11  12                        Xiph-2K   \n12  13                        Xiph-4k   \n13  14                          DAVIS   \n14  15                         VFITex   \n15  16                        ATD-12K   \n16  17                 Xiph-4K (Crop)   \n17  18           Nvidia Dynamic Scene   \n18  19                        Xiph 4k   \n\n                                                  url  \n0         /sota/video-frame-interpolation-on-vimeo90k  \n1   /sota/video-frame-interpolation-on-msu-video-f...  \n2         /sota/video-frame-interpolation-on-ucf101-1  \n3       /sota/video-frame-interpolation-on-x4k1000fps  \n4       /sota/video-frame-interpolation-on-middlebury  \n5          /sota/video-frame-interpolation-on-vid4-4x  \n6    /sota/video-frame-interpolation-on-snu-film-easy  \n7   /sota/video-frame-interpolation-on-snu-film-me...  \n8    /sota/video-frame-interpolation-on-snu-film-hard  \n9   /sota/video-frame-interpolation-on-snu-film-ex...  \n10   /sota/video-frame-interpolation-on-x4k1000fps-2k  \n11         /sota/video-frame-interpolation-on-xiph-2k  \n12       /sota/video-frame-interpolation-on-xiph-4k-1  \n13           /sota/video-frame-interpolation-on-davis  \n14          /sota/video-frame-interpolation-on-vfitex  \n15         /sota/video-frame-interpolation-on-atd-12k  \n16    /sota/video-frame-interpolation-on-xiph-4k-crop  \n17  /sota/video-frame-interpolation-on-nvidia-dynamic  \n18         /sota/video-frame-interpolation-on-xiph-4k  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Vimeo90K</td>\n      <td>/sota/video-frame-interpolation-on-vimeo90k</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>MSU Video Frame Interpolation</td>\n      <td>/sota/video-frame-interpolation-on-msu-video-f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>UCF101</td>\n      <td>/sota/video-frame-interpolation-on-ucf101-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>X4K1000FPS</td>\n      <td>/sota/video-frame-interpolation-on-x4k1000fps</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Middlebury</td>\n      <td>/sota/video-frame-interpolation-on-middlebury</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>Vid4 - 4x upscaling</td>\n      <td>/sota/video-frame-interpolation-on-vid4-4x</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>SNU-FILM (easy)</td>\n      <td>/sota/video-frame-interpolation-on-snu-film-easy</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>SNU-FILM (medium)</td>\n      <td>/sota/video-frame-interpolation-on-snu-film-me...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>SNU-FILM (hard)</td>\n      <td>/sota/video-frame-interpolation-on-snu-film-hard</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>SNU-FILM (extreme)</td>\n      <td>/sota/video-frame-interpolation-on-snu-film-ex...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>X4K1000FPS-2K</td>\n      <td>/sota/video-frame-interpolation-on-x4k1000fps-2k</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>Xiph-2K</td>\n      <td>/sota/video-frame-interpolation-on-xiph-2k</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>Xiph-4k</td>\n      <td>/sota/video-frame-interpolation-on-xiph-4k-1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>DAVIS</td>\n      <td>/sota/video-frame-interpolation-on-davis</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>VFITex</td>\n      <td>/sota/video-frame-interpolation-on-vfitex</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>ATD-12K</td>\n      <td>/sota/video-frame-interpolation-on-atd-12k</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>Xiph-4K (Crop)</td>\n      <td>/sota/video-frame-interpolation-on-xiph-4k-crop</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>Nvidia Dynamic Scene</td>\n      <td>/sota/video-frame-interpolation-on-nvidia-dynamic</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>Xiph 4k</td>\n      <td>/sota/video-frame-interpolation-on-xiph-4k</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmarks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      id  modelId  benchmarkId    psnr    ssim  lpips   \n0      1        1            1  36.760  0.9800    NaN  \\\n1      2        2            1  36.640  0.9819    NaN   \n2      3        3            1  36.420  0.9815    NaN   \n3      4        4            1  36.200  0.9808    NaN   \n4      5        5            1  36.190  0.9810    NaN   \n..   ...      ...          ...     ...     ...    ...   \n117  118       33           15  29.175     NaN    NaN   \n118  119       11           16  29.030  0.9590    NaN   \n119  120       11           17  33.930  0.9450    NaN   \n120  121       10           18  36.240  0.9839    NaN   \n121  122       10           19  30.940  0.9389    NaN   \n\n                                            detailHref  \n0    /paper/exploring-motion-ambiguity-and-alignmen...  \n1    /paper/extracting-motion-and-appearance-via-inter  \n2    /paper/a-unified-pyramid-recurrent-network-for...  \n3    /paper/ifrnet-intermediate-feature-refine-network  \n4    /paper/enhanced-bi-directional-motion-estimati...  \n..                                                 ...  \n117  /paper/spatio-temporal-multi-flow-network-for-...  \n118  /paper/many-to-many-splatting-for-efficient-video  \n119  /paper/many-to-many-splatting-for-efficient-video  \n120  /paper/learning-cross-video-neural-representat...  \n121  /paper/learning-cross-video-neural-representat...  \n\n[122 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>modelId</th>\n      <th>benchmarkId</th>\n      <th>psnr</th>\n      <th>ssim</th>\n      <th>lpips</th>\n      <th>detailHref</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>36.760</td>\n      <td>0.9800</td>\n      <td>NaN</td>\n      <td>/paper/exploring-motion-ambiguity-and-alignmen...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>36.640</td>\n      <td>0.9819</td>\n      <td>NaN</td>\n      <td>/paper/extracting-motion-and-appearance-via-inter</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>36.420</td>\n      <td>0.9815</td>\n      <td>NaN</td>\n      <td>/paper/a-unified-pyramid-recurrent-network-for...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>36.200</td>\n      <td>0.9808</td>\n      <td>NaN</td>\n      <td>/paper/ifrnet-intermediate-feature-refine-network</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>36.190</td>\n      <td>0.9810</td>\n      <td>NaN</td>\n      <td>/paper/enhanced-bi-directional-motion-estimati...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>118</td>\n      <td>33</td>\n      <td>15</td>\n      <td>29.175</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/paper/spatio-temporal-multi-flow-network-for-...</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>119</td>\n      <td>11</td>\n      <td>16</td>\n      <td>29.030</td>\n      <td>0.9590</td>\n      <td>NaN</td>\n      <td>/paper/many-to-many-splatting-for-efficient-video</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>120</td>\n      <td>11</td>\n      <td>17</td>\n      <td>33.930</td>\n      <td>0.9450</td>\n      <td>NaN</td>\n      <td>/paper/many-to-many-splatting-for-efficient-video</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>121</td>\n      <td>10</td>\n      <td>18</td>\n      <td>36.240</td>\n      <td>0.9839</td>\n      <td>NaN</td>\n      <td>/paper/learning-cross-video-neural-representat...</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>122</td>\n      <td>10</td>\n      <td>19</td>\n      <td>30.940</td>\n      <td>0.9389</td>\n      <td>NaN</td>\n      <td>/paper/learning-cross-video-neural-representat...</td>\n    </tr>\n  </tbody>\n</table>\n<p>122 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model2benchmarks = pd.read_sql_query(\"SELECT * from Model2Benchmarks\", database)\n",
    "df_model2benchmarks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1:     id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "0    1        1            1  36.76  0.9800    NaN  \\\n",
      "1    2        2            1  36.64  0.9819    NaN   \n",
      "2    3        3            1  36.42  0.9815    NaN   \n",
      "3    4        4            1  36.20  0.9808    NaN   \n",
      "4    5        5            1  36.19  0.9810    NaN   \n",
      "5    6        6            1  36.18  0.9805    NaN   \n",
      "6    7        7            1  36.10  0.9700    NaN   \n",
      "7    8        8            1  36.06  0.9700    NaN   \n",
      "8    9        9            1  35.88  0.9795    NaN   \n",
      "9   10       10            1  35.73  0.9789    NaN   \n",
      "10  11       11            1  35.40  0.9780    NaN   \n",
      "11  12       12            1  35.22  0.9643    NaN   \n",
      "12  13       13            1  35.17     NaN   0.01   \n",
      "13  14       14            1  35.07  0.9760    NaN   \n",
      "14  15       15            1  35.01  0.9764    NaN   \n",
      "15  16       16            1  34.95  0.9749    NaN   \n",
      "16  17       17            1  34.71  0.9756    NaN   \n",
      "17  18       17            1  34.71     NaN    NaN   \n",
      "18  19       18            1  34.65     NaN    NaN   \n",
      "19  20       19            1  34.40     NaN    NaN   \n",
      "20  21       20            1  33.80     NaN    NaN   \n",
      "21  22       21            1  33.73     NaN    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "0   /paper/exploring-motion-ambiguity-and-alignmen...  \n",
      "1   /paper/extracting-motion-and-appearance-via-inter  \n",
      "2   /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "3   /paper/ifrnet-intermediate-feature-refine-network  \n",
      "4   /paper/enhanced-bi-directional-motion-estimati...  \n",
      "5   /paper/asymmetric-bilateral-motion-estimation-for  \n",
      "6            /paper/softmax-splatting-for-video-frame  \n",
      "7    /paper/film-frame-interpolation-for-large-motion  \n",
      "8    /paper/neighbor-correspondence-matching-for-flow  \n",
      "9   /paper/learning-cross-video-neural-representat...  \n",
      "10  /paper/many-to-many-splatting-for-efficient-video  \n",
      "11       /paper/video-frame-interpolation-via-residue  \n",
      "12  /paper/cdfi-compression-driven-network-design-for  \n",
      "13      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "14       /paper/bmbc-bilateral-motion-estimation-with  \n",
      "15   /paper/enhanced-correlation-matching-based-video  \n",
      "16       /paper/depth-aware-video-frame-interpolation  \n",
      "17       /paper/depth-aware-video-frame-interpolation  \n",
      "18                                               null  \n",
      "19       /paper/memc-net-motion-estimation-and-motion  \n",
      "20      /paper/video-frame-interpolation-via-adaptive  \n",
      "21   /paper/video-enhancement-with-task-oriented-flow  , 2:     id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "22  23       22            2  27.15  0.914  0.039  \\\n",
      "23  24       23            2  27.35  0.913  0.061   \n",
      "24  25       24            2  26.69  0.904  0.068   \n",
      "25  26        2            2  29.89  0.953  0.022   \n",
      "26  27        3            2  29.73  0.951  0.025   \n",
      "27  28       25            2  28.77  0.931  0.024   \n",
      "28  29       26            2  28.56  0.928  0.028   \n",
      "29  30       27            2  28.34  0.917  0.044   \n",
      "30  31        8            2  28.11  0.928  0.033   \n",
      "31  32       10            2  28.01  0.920  0.029   \n",
      "32  33        6            2  27.99  0.919  0.039   \n",
      "33  34       28            2  27.86  0.921  0.049   \n",
      "34  35       13            2  26.99  0.908  0.051   \n",
      "35  36       29            2  24.99  0.903  0.058   \n",
      "36  37       30            2  24.48  0.902  0.060   \n",
      "37  38       15            2  23.34  0.885  0.071   \n",
      "38  39       31            2  23.28  0.889  0.070   \n",
      "39  40       32            2  23.17  0.891  0.692   \n",
      "\n",
      "                                           detailHref  \n",
      "22  /paper/rife-real-time-intermediate-flow-estima...  \n",
      "23      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "24      /paper/super-slomo-high-quality-estimation-of  \n",
      "25  /paper/extracting-motion-and-appearance-via-inter  \n",
      "26  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "27  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "28  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "29  /paper/video-frame-interpolation-with-transformer  \n",
      "30   /paper/film-frame-interpolation-for-large-motion  \n",
      "31  /paper/learning-cross-video-neural-representat...  \n",
      "32  /paper/asymmetric-bilateral-motion-estimation-for  \n",
      "33      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "34  /paper/cdfi-compression-driven-network-design-for  \n",
      "35  /paper/learning-spatial-transform-for-video-frame  \n",
      "36  /paper/featureflow-robust-video-interpolation-via  \n",
      "37     /paper/bmbc-bilateral-motion-estimation-with-1  \n",
      "38  /paper/featureflow-robust-video-interpolation-via  \n",
      "39  /paper/learning-spatial-transform-for-video-frame  , 3:     id  modelId  benchmarkId    psnr    ssim  lpips   \n",
      "40  41        2            3  35.480  0.9701    NaN  \\\n",
      "41  42        3            3  35.470  0.9700    NaN   \n",
      "42  43        1            3  35.430  0.9790    NaN   \n",
      "43  44        4            3  35.420  0.9698    NaN   \n",
      "44  45        5            3  35.410  0.9700    NaN   \n",
      "45  46        7            3  35.390  0.9520    NaN   \n",
      "46  47        6            3  35.380  0.9698    NaN   \n",
      "47  48       10            3  35.360  0.9705    NaN   \n",
      "48  49        9            3  35.360  0.9695    NaN   \n",
      "49  50        8            3  35.320  0.9520    NaN   \n",
      "50  51       13            3  35.210     NaN  0.015   \n",
      "51  52       11            3  35.170  0.9700    NaN   \n",
      "52  53       15            3  35.150  0.9689    NaN   \n",
      "53  54       17            3  34.990  0.9683    NaN   \n",
      "54  55       12            3  34.930  0.9496    NaN   \n",
      "55  56       33            3  33.384     NaN    NaN   \n",
      "56  57       34            3     NaN     NaN    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "40  /paper/extracting-motion-and-appearance-via-inter  \n",
      "41  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "42  /paper/exploring-motion-ambiguity-and-alignmen...  \n",
      "43  /paper/ifrnet-intermediate-feature-refine-network  \n",
      "44  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "45           /paper/softmax-splatting-for-video-frame  \n",
      "46  /paper/asymmetric-bilateral-motion-estimation-for  \n",
      "47  /paper/learning-cross-video-neural-representat...  \n",
      "48   /paper/neighbor-correspondence-matching-for-flow  \n",
      "49   /paper/film-frame-interpolation-for-large-motion  \n",
      "50  /paper/cdfi-compression-driven-network-design-for  \n",
      "51  /paper/many-to-many-splatting-for-efficient-video  \n",
      "52       /paper/bmbc-bilateral-motion-estimation-with  \n",
      "53       /paper/depth-aware-video-frame-interpolation  \n",
      "54       /paper/video-frame-interpolation-via-residue  \n",
      "55  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "56  /paper/unsupervised-video-interpolation-using-...  , 4:     id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "57  58        9            4  31.63  0.9185    NaN  \\\n",
      "58  59        2            4  31.46     NaN    NaN   \n",
      "59  60       11            4  30.81  0.9120    NaN   \n",
      "60  61       35            4  30.68  0.9086    NaN   \n",
      "61  62       16            4  30.51  0.8719    NaN   \n",
      "62  63        6            4  30.16  0.8793    NaN   \n",
      "63  64       36            4  30.12  0.8700    NaN   \n",
      "64  65        5            4  29.46  0.9020    NaN   \n",
      "65  66       37            4  28.86  0.8580    NaN   \n",
      "66  67       38            4  27.52  0.8210    NaN   \n",
      "67  68       17            4  26.78  0.8070    NaN   \n",
      "68  69       29            4  25.81  0.7720    NaN   \n",
      "69  70       30            4  25.16  0.7830    NaN   \n",
      "70  71       31            4  24.00  0.7560    NaN   \n",
      "71  72       32            4  23.90  0.7270    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "57   /paper/neighbor-correspondence-matching-for-flow  \n",
      "58  /paper/extracting-motion-and-appearance-via-inter  \n",
      "59  /paper/many-to-many-splatting-for-efficient-video  \n",
      "60  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "61   /paper/enhanced-correlation-matching-based-video  \n",
      "62  /paper/asymmetric-bilateral-motion-estimation-for  \n",
      "63      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "64  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "65      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "66       /paper/depth-aware-video-frame-interpolation  \n",
      "67       /paper/depth-aware-video-frame-interpolation  \n",
      "68  /paper/learning-spatial-transform-for-video-frame  \n",
      "69  /paper/featureflow-robust-video-interpolation-via  \n",
      "70  /paper/featureflow-robust-video-interpolation-via  \n",
      "71  /paper/learning-spatial-transform-for-video-frame  , 5:     id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "72  73        4            5    NaN    NaN    NaN  \\\n",
      "73  74        7            5  38.42  0.971    NaN   \n",
      "74  75       15            5    NaN    NaN    NaN   \n",
      "75  76       18            5    NaN    NaN    NaN   \n",
      "76  77       17            5    NaN    NaN    NaN   \n",
      "77  78       39            5    NaN    NaN    NaN   \n",
      "78  79       21            5    NaN    NaN    NaN   \n",
      "79  80       20            5    NaN    NaN    NaN   \n",
      "80  81        1            5  38.83    NaN    NaN   \n",
      "81  82        8            5  37.52  0.966    NaN   \n",
      "82  83       13            5  37.14  0.966  0.007   \n",
      "\n",
      "                                           detailHref  \n",
      "72  /paper/ifrnet-intermediate-feature-refine-network  \n",
      "73           /paper/softmax-splatting-for-video-frame  \n",
      "74       /paper/bmbc-bilateral-motion-estimation-with  \n",
      "75                                               null  \n",
      "76       /paper/depth-aware-video-frame-interpolation  \n",
      "77     /paper/memc-net-motion-estimation-and-motion-1  \n",
      "78   /paper/video-enhancement-with-task-oriented-flow  \n",
      "79      /paper/video-frame-interpolation-via-adaptive  \n",
      "80  /paper/exploring-motion-ambiguity-and-alignmen...  \n",
      "81   /paper/film-frame-interpolation-for-large-motion  \n",
      "82  /paper/cdfi-compression-driven-network-design-for  , 6:     id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "83  84       40            6  27.46  0.8392    NaN  \\\n",
      "84  85       41            6  26.43  0.7994    NaN   \n",
      "85  86       42            6  26.37  0.7978    NaN   \n",
      "86  87       43            6  26.31  0.7976    NaN   \n",
      "87  88       44            6  26.29  0.7941    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "83         /paper/vrt-a-video-restoration-transformer  \n",
      "84  /paper/rstt-real-time-spatial-temporal-transfo...  \n",
      "85  /paper/rstt-real-time-spatial-temporal-transfo...  \n",
      "86  /paper/zooming-slow-mo-fast-and-accurate-one-s...  \n",
      "87  /paper/rstt-real-time-spatial-temporal-transfo...  , 7:     id  modelId  benchmarkId    psnr    ssim  lpips   \n",
      "88  89       33            7  40.775     NaN    NaN  \\\n",
      "89  90        3            7  40.440  0.9911    NaN   \n",
      "90  91        5            7  40.280  0.9910    NaN   \n",
      "91  92        2            7  39.980  0.9910    NaN   \n",
      "92  93       10            7  39.900  0.9910    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "88  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "89  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "90  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "91  /paper/extracting-motion-and-appearance-via-inter  \n",
      "92  /paper/learning-cross-video-neural-representat...  , 8:     id  modelId  benchmarkId    psnr    ssim  lpips   \n",
      "93  94       33            8  37.111     NaN    NaN  \\\n",
      "94  95        3            8  36.290  0.9801    NaN   \n",
      "95  96        2            8  36.090  0.9801    NaN   \n",
      "96  97        5            8  36.070  0.9800    NaN   \n",
      "97  98       10            8  35.940  0.9797    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "93  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "94  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "95  /paper/extracting-motion-and-appearance-via-inter  \n",
      "96  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "97  /paper/learning-cross-video-neural-representat...  , 9:       id  modelId  benchmarkId    psnr    ssim  lpips   \n",
      "98    99       33            9  31.698     NaN    NaN  \\\n",
      "99   100        2            9  30.940  0.9392    NaN   \n",
      "100  101        3            9  30.860  0.9377    NaN   \n",
      "101  102       10            9  30.660  0.9373    NaN   \n",
      "102  103        5            9  30.640  0.9370    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "98   /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "99   /paper/extracting-motion-and-appearance-via-inter  \n",
      "100  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "101  /paper/learning-cross-video-neural-representat...  \n",
      "102  /paper/enhanced-bi-directional-motion-estimati...  , 10:       id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "103  104       33           10  25.81     NaN    NaN  \\\n",
      "104  105        2           10  25.69  0.8661    NaN   \n",
      "105  106        3           10  25.63  0.8641    NaN   \n",
      "106  107       10           10  25.44  0.8638    NaN   \n",
      "107  108        5           10  25.40  0.8630    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "103  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "104  /paper/extracting-motion-and-appearance-via-inter  \n",
      "105  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "106  /paper/learning-cross-video-neural-representat...  \n",
      "107  /paper/enhanced-bi-directional-motion-estimati...  , 11:       id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "108  109        2           11  32.85     NaN    NaN  \\\n",
      "109  110       11           11  32.07  0.9230    NaN   \n",
      "110  111       10           11  30.05  0.8998    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "108  /paper/extracting-motion-and-appearance-via-inter  \n",
      "109  /paper/many-to-many-splatting-for-efficient-video  \n",
      "110  /paper/learning-cross-video-neural-representat...  , 12:       id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "111  112        2           12  36.90  0.945    NaN  \\\n",
      "112  113        8           12  36.66  0.951    NaN   \n",
      "113  114       11           12  36.45  0.967    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "111  /paper/extracting-motion-and-appearance-via-inter  \n",
      "112   /paper/film-frame-interpolation-for-large-motion  \n",
      "113  /paper/many-to-many-splatting-for-efficient-video  , 13:       id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "114  115        2           13  34.67  0.907    NaN  \\\n",
      "115  116        8           13  33.78  0.906    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "114  /paper/extracting-motion-and-appearance-via-inter  \n",
      "115   /paper/film-frame-interpolation-for-large-motion  , 14:       id  modelId  benchmarkId    psnr  ssim  lpips   \n",
      "116  117       33           14  28.287   NaN    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "116  /paper/spatio-temporal-multi-flow-network-for-...  , 15:       id  modelId  benchmarkId    psnr  ssim  lpips   \n",
      "117  118       33           15  29.175   NaN    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "117  /paper/spatio-temporal-multi-flow-network-for-...  , 16:       id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "118  119       11           16  29.03  0.959    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "118  /paper/many-to-many-splatting-for-efficient-video  , 17:       id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "119  120       11           17  33.93  0.945    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "119  /paper/many-to-many-splatting-for-efficient-video  , 18:       id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "120  121       10           18  36.24  0.9839    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "120  /paper/learning-cross-video-neural-representat...  , 19:       id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "121  122       10           19  30.94  0.9389    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "121  /paper/learning-cross-video-neural-representat...  }\n"
     ]
    }
   ],
   "source": [
    "top10 = []\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "0    1        1            1  36.76  0.9800    NaN  \\\n",
      "1    2        2            1  36.64  0.9819    NaN   \n",
      "2    3        3            1  36.42  0.9815    NaN   \n",
      "3    4        4            1  36.20  0.9808    NaN   \n",
      "4    5        5            1  36.19  0.9810    NaN   \n",
      "5    6        6            1  36.18  0.9805    NaN   \n",
      "6    7        7            1  36.10  0.9700    NaN   \n",
      "7    8        8            1  36.06  0.9700    NaN   \n",
      "8    9        9            1  35.88  0.9795    NaN   \n",
      "9   10       10            1  35.73  0.9789    NaN   \n",
      "10  11       11            1  35.40  0.9780    NaN   \n",
      "11  12       12            1  35.22  0.9643    NaN   \n",
      "12  13       13            1  35.17     NaN   0.01   \n",
      "13  14       14            1  35.07  0.9760    NaN   \n",
      "14  15       15            1  35.01  0.9764    NaN   \n",
      "15  16       16            1  34.95  0.9749    NaN   \n",
      "16  17       17            1  34.71  0.9756    NaN   \n",
      "17  18       17            1  34.71     NaN    NaN   \n",
      "18  19       18            1  34.65     NaN    NaN   \n",
      "19  20       19            1  34.40     NaN    NaN   \n",
      "20  21       20            1  33.80     NaN    NaN   \n",
      "21  22       21            1  33.73     NaN    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "0   /paper/exploring-motion-ambiguity-and-alignmen...  \n",
      "1   /paper/extracting-motion-and-appearance-via-inter  \n",
      "2   /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "3   /paper/ifrnet-intermediate-feature-refine-network  \n",
      "4   /paper/enhanced-bi-directional-motion-estimati...  \n",
      "5   /paper/asymmetric-bilateral-motion-estimation-for  \n",
      "6            /paper/softmax-splatting-for-video-frame  \n",
      "7    /paper/film-frame-interpolation-for-large-motion  \n",
      "8    /paper/neighbor-correspondence-matching-for-flow  \n",
      "9   /paper/learning-cross-video-neural-representat...  \n",
      "10  /paper/many-to-many-splatting-for-efficient-video  \n",
      "11       /paper/video-frame-interpolation-via-residue  \n",
      "12  /paper/cdfi-compression-driven-network-design-for  \n",
      "13      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "14       /paper/bmbc-bilateral-motion-estimation-with  \n",
      "15   /paper/enhanced-correlation-matching-based-video  \n",
      "16       /paper/depth-aware-video-frame-interpolation  \n",
      "17       /paper/depth-aware-video-frame-interpolation  \n",
      "18                                               null  \n",
      "19       /paper/memc-net-motion-estimation-and-motion  \n",
      "20      /paper/video-frame-interpolation-via-adaptive  \n",
      "21   /paper/video-enhancement-with-task-oriented-flow  \n",
      "    id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "22  23       22            2  27.15  0.914  0.039  \\\n",
      "23  24       23            2  27.35  0.913  0.061   \n",
      "24  25       24            2  26.69  0.904  0.068   \n",
      "25  26        2            2  29.89  0.953  0.022   \n",
      "26  27        3            2  29.73  0.951  0.025   \n",
      "27  28       25            2  28.77  0.931  0.024   \n",
      "28  29       26            2  28.56  0.928  0.028   \n",
      "29  30       27            2  28.34  0.917  0.044   \n",
      "30  31        8            2  28.11  0.928  0.033   \n",
      "31  32       10            2  28.01  0.920  0.029   \n",
      "32  33        6            2  27.99  0.919  0.039   \n",
      "33  34       28            2  27.86  0.921  0.049   \n",
      "34  35       13            2  26.99  0.908  0.051   \n",
      "35  36       29            2  24.99  0.903  0.058   \n",
      "36  37       30            2  24.48  0.902  0.060   \n",
      "37  38       15            2  23.34  0.885  0.071   \n",
      "38  39       31            2  23.28  0.889  0.070   \n",
      "39  40       32            2  23.17  0.891  0.692   \n",
      "\n",
      "                                           detailHref  \n",
      "22  /paper/rife-real-time-intermediate-flow-estima...  \n",
      "23      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "24      /paper/super-slomo-high-quality-estimation-of  \n",
      "25  /paper/extracting-motion-and-appearance-via-inter  \n",
      "26  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "27  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "28  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "29  /paper/video-frame-interpolation-with-transformer  \n",
      "30   /paper/film-frame-interpolation-for-large-motion  \n",
      "31  /paper/learning-cross-video-neural-representat...  \n",
      "32  /paper/asymmetric-bilateral-motion-estimation-for  \n",
      "33      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "34  /paper/cdfi-compression-driven-network-design-for  \n",
      "35  /paper/learning-spatial-transform-for-video-frame  \n",
      "36  /paper/featureflow-robust-video-interpolation-via  \n",
      "37     /paper/bmbc-bilateral-motion-estimation-with-1  \n",
      "38  /paper/featureflow-robust-video-interpolation-via  \n",
      "39  /paper/learning-spatial-transform-for-video-frame  \n",
      "    id  modelId  benchmarkId    psnr    ssim  lpips   \n",
      "40  41        2            3  35.480  0.9701    NaN  \\\n",
      "41  42        3            3  35.470  0.9700    NaN   \n",
      "42  43        1            3  35.430  0.9790    NaN   \n",
      "43  44        4            3  35.420  0.9698    NaN   \n",
      "44  45        5            3  35.410  0.9700    NaN   \n",
      "45  46        7            3  35.390  0.9520    NaN   \n",
      "46  47        6            3  35.380  0.9698    NaN   \n",
      "47  48       10            3  35.360  0.9705    NaN   \n",
      "48  49        9            3  35.360  0.9695    NaN   \n",
      "49  50        8            3  35.320  0.9520    NaN   \n",
      "50  51       13            3  35.210     NaN  0.015   \n",
      "51  52       11            3  35.170  0.9700    NaN   \n",
      "52  53       15            3  35.150  0.9689    NaN   \n",
      "53  54       17            3  34.990  0.9683    NaN   \n",
      "54  55       12            3  34.930  0.9496    NaN   \n",
      "55  56       33            3  33.384     NaN    NaN   \n",
      "56  57       34            3     NaN     NaN    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "40  /paper/extracting-motion-and-appearance-via-inter  \n",
      "41  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "42  /paper/exploring-motion-ambiguity-and-alignmen...  \n",
      "43  /paper/ifrnet-intermediate-feature-refine-network  \n",
      "44  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "45           /paper/softmax-splatting-for-video-frame  \n",
      "46  /paper/asymmetric-bilateral-motion-estimation-for  \n",
      "47  /paper/learning-cross-video-neural-representat...  \n",
      "48   /paper/neighbor-correspondence-matching-for-flow  \n",
      "49   /paper/film-frame-interpolation-for-large-motion  \n",
      "50  /paper/cdfi-compression-driven-network-design-for  \n",
      "51  /paper/many-to-many-splatting-for-efficient-video  \n",
      "52       /paper/bmbc-bilateral-motion-estimation-with  \n",
      "53       /paper/depth-aware-video-frame-interpolation  \n",
      "54       /paper/video-frame-interpolation-via-residue  \n",
      "55  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "56  /paper/unsupervised-video-interpolation-using-...  \n",
      "    id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "57  58        9            4  31.63  0.9185    NaN  \\\n",
      "58  59        2            4  31.46     NaN    NaN   \n",
      "59  60       11            4  30.81  0.9120    NaN   \n",
      "60  61       35            4  30.68  0.9086    NaN   \n",
      "61  62       16            4  30.51  0.8719    NaN   \n",
      "62  63        6            4  30.16  0.8793    NaN   \n",
      "63  64       36            4  30.12  0.8700    NaN   \n",
      "64  65        5            4  29.46  0.9020    NaN   \n",
      "65  66       37            4  28.86  0.8580    NaN   \n",
      "66  67       38            4  27.52  0.8210    NaN   \n",
      "67  68       17            4  26.78  0.8070    NaN   \n",
      "68  69       29            4  25.81  0.7720    NaN   \n",
      "69  70       30            4  25.16  0.7830    NaN   \n",
      "70  71       31            4  24.00  0.7560    NaN   \n",
      "71  72       32            4  23.90  0.7270    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "57   /paper/neighbor-correspondence-matching-for-flow  \n",
      "58  /paper/extracting-motion-and-appearance-via-inter  \n",
      "59  /paper/many-to-many-splatting-for-efficient-video  \n",
      "60  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "61   /paper/enhanced-correlation-matching-based-video  \n",
      "62  /paper/asymmetric-bilateral-motion-estimation-for  \n",
      "63      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "64  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "65      /paper/xvfi-extreme-video-frame-interpolation  \n",
      "66       /paper/depth-aware-video-frame-interpolation  \n",
      "67       /paper/depth-aware-video-frame-interpolation  \n",
      "68  /paper/learning-spatial-transform-for-video-frame  \n",
      "69  /paper/featureflow-robust-video-interpolation-via  \n",
      "70  /paper/featureflow-robust-video-interpolation-via  \n",
      "71  /paper/learning-spatial-transform-for-video-frame  \n",
      "    id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "72  73        4            5    NaN    NaN    NaN  \\\n",
      "73  74        7            5  38.42  0.971    NaN   \n",
      "74  75       15            5    NaN    NaN    NaN   \n",
      "75  76       18            5    NaN    NaN    NaN   \n",
      "76  77       17            5    NaN    NaN    NaN   \n",
      "77  78       39            5    NaN    NaN    NaN   \n",
      "78  79       21            5    NaN    NaN    NaN   \n",
      "79  80       20            5    NaN    NaN    NaN   \n",
      "80  81        1            5  38.83    NaN    NaN   \n",
      "81  82        8            5  37.52  0.966    NaN   \n",
      "82  83       13            5  37.14  0.966  0.007   \n",
      "\n",
      "                                           detailHref  \n",
      "72  /paper/ifrnet-intermediate-feature-refine-network  \n",
      "73           /paper/softmax-splatting-for-video-frame  \n",
      "74       /paper/bmbc-bilateral-motion-estimation-with  \n",
      "75                                               null  \n",
      "76       /paper/depth-aware-video-frame-interpolation  \n",
      "77     /paper/memc-net-motion-estimation-and-motion-1  \n",
      "78   /paper/video-enhancement-with-task-oriented-flow  \n",
      "79      /paper/video-frame-interpolation-via-adaptive  \n",
      "80  /paper/exploring-motion-ambiguity-and-alignmen...  \n",
      "81   /paper/film-frame-interpolation-for-large-motion  \n",
      "82  /paper/cdfi-compression-driven-network-design-for  \n",
      "    id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "83  84       40            6  27.46  0.8392    NaN  \\\n",
      "84  85       41            6  26.43  0.7994    NaN   \n",
      "85  86       42            6  26.37  0.7978    NaN   \n",
      "86  87       43            6  26.31  0.7976    NaN   \n",
      "87  88       44            6  26.29  0.7941    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "83         /paper/vrt-a-video-restoration-transformer  \n",
      "84  /paper/rstt-real-time-spatial-temporal-transfo...  \n",
      "85  /paper/rstt-real-time-spatial-temporal-transfo...  \n",
      "86  /paper/zooming-slow-mo-fast-and-accurate-one-s...  \n",
      "87  /paper/rstt-real-time-spatial-temporal-transfo...  \n",
      "    id  modelId  benchmarkId    psnr    ssim  lpips   \n",
      "88  89       33            7  40.775     NaN    NaN  \\\n",
      "89  90        3            7  40.440  0.9911    NaN   \n",
      "90  91        5            7  40.280  0.9910    NaN   \n",
      "91  92        2            7  39.980  0.9910    NaN   \n",
      "92  93       10            7  39.900  0.9910    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "88  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "89  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "90  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "91  /paper/extracting-motion-and-appearance-via-inter  \n",
      "92  /paper/learning-cross-video-neural-representat...  \n",
      "    id  modelId  benchmarkId    psnr    ssim  lpips   \n",
      "93  94       33            8  37.111     NaN    NaN  \\\n",
      "94  95        3            8  36.290  0.9801    NaN   \n",
      "95  96        2            8  36.090  0.9801    NaN   \n",
      "96  97        5            8  36.070  0.9800    NaN   \n",
      "97  98       10            8  35.940  0.9797    NaN   \n",
      "\n",
      "                                           detailHref  \n",
      "93  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "94  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "95  /paper/extracting-motion-and-appearance-via-inter  \n",
      "96  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "97  /paper/learning-cross-video-neural-representat...  \n",
      "      id  modelId  benchmarkId    psnr    ssim  lpips   \n",
      "98    99       33            9  31.698     NaN    NaN  \\\n",
      "99   100        2            9  30.940  0.9392    NaN   \n",
      "100  101        3            9  30.860  0.9377    NaN   \n",
      "101  102       10            9  30.660  0.9373    NaN   \n",
      "102  103        5            9  30.640  0.9370    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "98   /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "99   /paper/extracting-motion-and-appearance-via-inter  \n",
      "100  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "101  /paper/learning-cross-video-neural-representat...  \n",
      "102  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "      id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "103  104       33           10  25.81     NaN    NaN  \\\n",
      "104  105        2           10  25.69  0.8661    NaN   \n",
      "105  106        3           10  25.63  0.8641    NaN   \n",
      "106  107       10           10  25.44  0.8638    NaN   \n",
      "107  108        5           10  25.40  0.8630    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "103  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "104  /paper/extracting-motion-and-appearance-via-inter  \n",
      "105  /paper/a-unified-pyramid-recurrent-network-for...  \n",
      "106  /paper/learning-cross-video-neural-representat...  \n",
      "107  /paper/enhanced-bi-directional-motion-estimati...  \n",
      "      id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "108  109        2           11  32.85     NaN    NaN  \\\n",
      "109  110       11           11  32.07  0.9230    NaN   \n",
      "110  111       10           11  30.05  0.8998    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "108  /paper/extracting-motion-and-appearance-via-inter  \n",
      "109  /paper/many-to-many-splatting-for-efficient-video  \n",
      "110  /paper/learning-cross-video-neural-representat...  \n",
      "      id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "111  112        2           12  36.90  0.945    NaN  \\\n",
      "112  113        8           12  36.66  0.951    NaN   \n",
      "113  114       11           12  36.45  0.967    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "111  /paper/extracting-motion-and-appearance-via-inter  \n",
      "112   /paper/film-frame-interpolation-for-large-motion  \n",
      "113  /paper/many-to-many-splatting-for-efficient-video  \n",
      "      id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "114  115        2           13  34.67  0.907    NaN  \\\n",
      "115  116        8           13  33.78  0.906    NaN   \n",
      "\n",
      "                                            detailHref  \n",
      "114  /paper/extracting-motion-and-appearance-via-inter  \n",
      "115   /paper/film-frame-interpolation-for-large-motion  \n",
      "      id  modelId  benchmarkId    psnr  ssim  lpips   \n",
      "116  117       33           14  28.287   NaN    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "116  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "      id  modelId  benchmarkId    psnr  ssim  lpips   \n",
      "117  118       33           15  29.175   NaN    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "117  /paper/spatio-temporal-multi-flow-network-for-...  \n",
      "      id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "118  119       11           16  29.03  0.959    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "118  /paper/many-to-many-splatting-for-efficient-video  \n",
      "      id  modelId  benchmarkId   psnr   ssim  lpips   \n",
      "119  120       11           17  33.93  0.945    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "119  /paper/many-to-many-splatting-for-efficient-video  \n",
      "      id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "120  121       10           18  36.24  0.9839    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "120  /paper/learning-cross-video-neural-representat...  \n",
      "      id  modelId  benchmarkId   psnr    ssim  lpips   \n",
      "121  122       10           19  30.94  0.9389    NaN  \\\n",
      "\n",
      "                                            detailHref  \n",
      "121  /paper/learning-cross-video-neural-representat...  \n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n",
      "C:\\Users\\lordo\\AppData\\Local\\Temp\\ipykernel_16228\\3798537404.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b1[\"score\"] = score_list\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      id  modelId  benchmarkId    psnr    ssim  lpips   \n0      1        1            1  36.760  0.9800    NaN  \\\n1      2        2            1  36.640  0.9819    NaN   \n2      3        3            1  36.420  0.9815    NaN   \n3      4        4            1  36.200  0.9808    NaN   \n4      5        5            1  36.190  0.9810    NaN   \n..   ...      ...          ...     ...     ...    ...   \n117  118       33           15  29.175     NaN    NaN   \n118  119       11           16  29.030  0.9590    NaN   \n119  120       11           17  33.930  0.9450    NaN   \n120  121       10           18  36.240  0.9839    NaN   \n121  122       10           19  30.940  0.9389    NaN   \n\n                                            detailHref     score  \n0    /paper/exploring-motion-ambiguity-and-alignmen...  1.000000  \n1    /paper/extracting-motion-and-appearance-via-inter  0.954545  \n2    /paper/a-unified-pyramid-recurrent-network-for...  0.909091  \n3    /paper/ifrnet-intermediate-feature-refine-network  0.863636  \n4    /paper/enhanced-bi-directional-motion-estimati...  0.818182  \n..                                                 ...       ...  \n117  /paper/spatio-temporal-multi-flow-network-for-...  1.000000  \n118  /paper/many-to-many-splatting-for-efficient-video  1.000000  \n119  /paper/many-to-many-splatting-for-efficient-video  1.000000  \n120  /paper/learning-cross-video-neural-representat...  1.000000  \n121  /paper/learning-cross-video-neural-representat...  1.000000  \n\n[122 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>modelId</th>\n      <th>benchmarkId</th>\n      <th>psnr</th>\n      <th>ssim</th>\n      <th>lpips</th>\n      <th>detailHref</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>36.760</td>\n      <td>0.9800</td>\n      <td>NaN</td>\n      <td>/paper/exploring-motion-ambiguity-and-alignmen...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>36.640</td>\n      <td>0.9819</td>\n      <td>NaN</td>\n      <td>/paper/extracting-motion-and-appearance-via-inter</td>\n      <td>0.954545</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>36.420</td>\n      <td>0.9815</td>\n      <td>NaN</td>\n      <td>/paper/a-unified-pyramid-recurrent-network-for...</td>\n      <td>0.909091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>36.200</td>\n      <td>0.9808</td>\n      <td>NaN</td>\n      <td>/paper/ifrnet-intermediate-feature-refine-network</td>\n      <td>0.863636</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>36.190</td>\n      <td>0.9810</td>\n      <td>NaN</td>\n      <td>/paper/enhanced-bi-directional-motion-estimati...</td>\n      <td>0.818182</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>118</td>\n      <td>33</td>\n      <td>15</td>\n      <td>29.175</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/paper/spatio-temporal-multi-flow-network-for-...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>119</td>\n      <td>11</td>\n      <td>16</td>\n      <td>29.030</td>\n      <td>0.9590</td>\n      <td>NaN</td>\n      <td>/paper/many-to-many-splatting-for-efficient-video</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>120</td>\n      <td>11</td>\n      <td>17</td>\n      <td>33.930</td>\n      <td>0.9450</td>\n      <td>NaN</td>\n      <td>/paper/many-to-many-splatting-for-efficient-video</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>121</td>\n      <td>10</td>\n      <td>18</td>\n      <td>36.240</td>\n      <td>0.9839</td>\n      <td>NaN</td>\n      <td>/paper/learning-cross-video-neural-representat...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>122</td>\n      <td>10</td>\n      <td>19</td>\n      <td>30.940</td>\n      <td>0.9389</td>\n      <td>NaN</td>\n      <td>/paper/learning-cross-video-neural-representat...</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>122 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  benchmarkId    psnr    ssim  lpips   \nmodelId                                            \n1        125            9  111.02  1.9590  0.000  \\\n2        857           80  370.59  8.5334  0.022   \n3        464           40  234.84  6.6755  0.025   \n4        121            9   71.62  1.9506  0.000   \n5        514           42  233.45  6.6240  0.000   \n6        149           10  129.71  3.7486  0.039   \n7        127            9  109.91  2.8930  0.000   \n8        400           36  207.45  5.6730  0.033   \n9        116            8  102.87  2.8675  0.000   \n10       844           88  328.27  9.4638  0.029   \n11       586           64  232.86  6.6540  0.000   \n12        67            4   70.15  1.9139  0.000   \n13       182           11  134.51  1.8740  0.083   \n14        14            1   35.07  0.9760  0.000   \n15       181           11   93.50  2.8303  0.071   \n16        78            5   65.46  1.8468  0.000   \n17       234           14  131.19  2.7509  0.000   \n18        95            6   34.65  0.0000  0.000   \n19        20            1   34.40  0.0000  0.000   \n20       101            6   33.80  0.0000  0.000   \n21       101            6   33.73  0.0000  0.000   \n22        23            2   27.15  0.9140  0.039   \n23        24            2   27.35  0.9130  0.061   \n24        25            2   26.69  0.9040  0.068   \n25        28            2   28.77  0.9310  0.024   \n26        29            2   28.56  0.9280  0.028   \n27        30            2   28.34  0.9170  0.044   \n28        34            2   27.86  0.9210  0.049   \n29       105            6   50.80  1.6750  0.058   \n30       107            6   49.64  1.6850  0.060   \n\n                                                detailHref     score  \nmodelId                                                               \n1        /paper/exploring-motion-ambiguity-and-alignmen...  2.155080  \n2        /paper/extracting-motion-and-appearance-via-in...  9.321212  \n3        /paper/a-unified-pyramid-recurrent-network-for...  5.428045  \n4        /paper/ifrnet-intermediate-feature-refine-netw...  2.687166  \n5        /paper/enhanced-bi-directional-motion-estimati...  3.516221  \n6        /paper/asymmetric-bilateral-motion-estimation-...  2.530897  \n7        /paper/softmax-splatting-for-video-frame/paper...  2.342246  \n8        /paper/film-frame-interpolation-for-large-moti...  3.056447  \n9        /paper/neighbor-correspondence-matching-for-fl...  2.165775  \n10       /paper/learning-cross-video-neural-representat...  5.212478  \n11       /paper/many-to-many-splatting-for-efficient-vi...  4.765062  \n12       /paper/video-frame-interpolation-via-residue/p...  0.676471  \n13       /paper/cdfi-compression-driven-network-design-...  1.290553  \n14           /paper/xvfi-extreme-video-frame-interpolation  0.409091  \n15       /paper/bmbc-bilateral-motion-estimation-with/p...  1.642602  \n16       /paper/enhanced-correlation-matching-based-vid...  1.051515  \n17       /paper/depth-aware-video-frame-interpolation/p...  1.704991  \n18                                                nullnull  0.909091  \n19            /paper/memc-net-motion-estimation-and-motion  0.136364  \n20       /paper/video-frame-interpolation-via-adaptive/...  0.454545  \n21       /paper/video-enhancement-with-task-oriented-fl...  0.500000  \n22       /paper/rife-real-time-intermediate-flow-estima...  1.000000  \n23           /paper/xvfi-extreme-video-frame-interpolation  0.944444  \n24           /paper/super-slomo-high-quality-estimation-of  0.888889  \n25       /paper/enhanced-bi-directional-motion-estimati...  0.722222  \n26       /paper/enhanced-bi-directional-motion-estimati...  0.666667  \n27       /paper/video-frame-interpolation-with-transformer  0.611111  \n28           /paper/xvfi-extreme-video-frame-interpolation  0.388889  \n29       /paper/learning-spatial-transform-for-video-fr...  0.544444  \n30       /paper/featureflow-robust-video-interpolation-...  0.422222  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>benchmarkId</th>\n      <th>psnr</th>\n      <th>ssim</th>\n      <th>lpips</th>\n      <th>detailHref</th>\n      <th>score</th>\n    </tr>\n    <tr>\n      <th>modelId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>125</td>\n      <td>9</td>\n      <td>111.02</td>\n      <td>1.9590</td>\n      <td>0.000</td>\n      <td>/paper/exploring-motion-ambiguity-and-alignmen...</td>\n      <td>2.155080</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>857</td>\n      <td>80</td>\n      <td>370.59</td>\n      <td>8.5334</td>\n      <td>0.022</td>\n      <td>/paper/extracting-motion-and-appearance-via-in...</td>\n      <td>9.321212</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>464</td>\n      <td>40</td>\n      <td>234.84</td>\n      <td>6.6755</td>\n      <td>0.025</td>\n      <td>/paper/a-unified-pyramid-recurrent-network-for...</td>\n      <td>5.428045</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>121</td>\n      <td>9</td>\n      <td>71.62</td>\n      <td>1.9506</td>\n      <td>0.000</td>\n      <td>/paper/ifrnet-intermediate-feature-refine-netw...</td>\n      <td>2.687166</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>514</td>\n      <td>42</td>\n      <td>233.45</td>\n      <td>6.6240</td>\n      <td>0.000</td>\n      <td>/paper/enhanced-bi-directional-motion-estimati...</td>\n      <td>3.516221</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>149</td>\n      <td>10</td>\n      <td>129.71</td>\n      <td>3.7486</td>\n      <td>0.039</td>\n      <td>/paper/asymmetric-bilateral-motion-estimation-...</td>\n      <td>2.530897</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>127</td>\n      <td>9</td>\n      <td>109.91</td>\n      <td>2.8930</td>\n      <td>0.000</td>\n      <td>/paper/softmax-splatting-for-video-frame/paper...</td>\n      <td>2.342246</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>400</td>\n      <td>36</td>\n      <td>207.45</td>\n      <td>5.6730</td>\n      <td>0.033</td>\n      <td>/paper/film-frame-interpolation-for-large-moti...</td>\n      <td>3.056447</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>116</td>\n      <td>8</td>\n      <td>102.87</td>\n      <td>2.8675</td>\n      <td>0.000</td>\n      <td>/paper/neighbor-correspondence-matching-for-fl...</td>\n      <td>2.165775</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>844</td>\n      <td>88</td>\n      <td>328.27</td>\n      <td>9.4638</td>\n      <td>0.029</td>\n      <td>/paper/learning-cross-video-neural-representat...</td>\n      <td>5.212478</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>586</td>\n      <td>64</td>\n      <td>232.86</td>\n      <td>6.6540</td>\n      <td>0.000</td>\n      <td>/paper/many-to-many-splatting-for-efficient-vi...</td>\n      <td>4.765062</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>67</td>\n      <td>4</td>\n      <td>70.15</td>\n      <td>1.9139</td>\n      <td>0.000</td>\n      <td>/paper/video-frame-interpolation-via-residue/p...</td>\n      <td>0.676471</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>182</td>\n      <td>11</td>\n      <td>134.51</td>\n      <td>1.8740</td>\n      <td>0.083</td>\n      <td>/paper/cdfi-compression-driven-network-design-...</td>\n      <td>1.290553</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>1</td>\n      <td>35.07</td>\n      <td>0.9760</td>\n      <td>0.000</td>\n      <td>/paper/xvfi-extreme-video-frame-interpolation</td>\n      <td>0.409091</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>181</td>\n      <td>11</td>\n      <td>93.50</td>\n      <td>2.8303</td>\n      <td>0.071</td>\n      <td>/paper/bmbc-bilateral-motion-estimation-with/p...</td>\n      <td>1.642602</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>78</td>\n      <td>5</td>\n      <td>65.46</td>\n      <td>1.8468</td>\n      <td>0.000</td>\n      <td>/paper/enhanced-correlation-matching-based-vid...</td>\n      <td>1.051515</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>234</td>\n      <td>14</td>\n      <td>131.19</td>\n      <td>2.7509</td>\n      <td>0.000</td>\n      <td>/paper/depth-aware-video-frame-interpolation/p...</td>\n      <td>1.704991</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>95</td>\n      <td>6</td>\n      <td>34.65</td>\n      <td>0.0000</td>\n      <td>0.000</td>\n      <td>nullnull</td>\n      <td>0.909091</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>1</td>\n      <td>34.40</td>\n      <td>0.0000</td>\n      <td>0.000</td>\n      <td>/paper/memc-net-motion-estimation-and-motion</td>\n      <td>0.136364</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>101</td>\n      <td>6</td>\n      <td>33.80</td>\n      <td>0.0000</td>\n      <td>0.000</td>\n      <td>/paper/video-frame-interpolation-via-adaptive/...</td>\n      <td>0.454545</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>101</td>\n      <td>6</td>\n      <td>33.73</td>\n      <td>0.0000</td>\n      <td>0.000</td>\n      <td>/paper/video-enhancement-with-task-oriented-fl...</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>2</td>\n      <td>27.15</td>\n      <td>0.9140</td>\n      <td>0.039</td>\n      <td>/paper/rife-real-time-intermediate-flow-estima...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>2</td>\n      <td>27.35</td>\n      <td>0.9130</td>\n      <td>0.061</td>\n      <td>/paper/xvfi-extreme-video-frame-interpolation</td>\n      <td>0.944444</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>2</td>\n      <td>26.69</td>\n      <td>0.9040</td>\n      <td>0.068</td>\n      <td>/paper/super-slomo-high-quality-estimation-of</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>28</td>\n      <td>2</td>\n      <td>28.77</td>\n      <td>0.9310</td>\n      <td>0.024</td>\n      <td>/paper/enhanced-bi-directional-motion-estimati...</td>\n      <td>0.722222</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>29</td>\n      <td>2</td>\n      <td>28.56</td>\n      <td>0.9280</td>\n      <td>0.028</td>\n      <td>/paper/enhanced-bi-directional-motion-estimati...</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>30</td>\n      <td>2</td>\n      <td>28.34</td>\n      <td>0.9170</td>\n      <td>0.044</td>\n      <td>/paper/video-frame-interpolation-with-transformer</td>\n      <td>0.611111</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>34</td>\n      <td>2</td>\n      <td>27.86</td>\n      <td>0.9210</td>\n      <td>0.049</td>\n      <td>/paper/xvfi-extreme-video-frame-interpolation</td>\n      <td>0.388889</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>105</td>\n      <td>6</td>\n      <td>50.80</td>\n      <td>1.6750</td>\n      <td>0.058</td>\n      <td>/paper/learning-spatial-transform-for-video-fr...</td>\n      <td>0.544444</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>107</td>\n      <td>6</td>\n      <td>49.64</td>\n      <td>1.6850</td>\n      <td>0.060</td>\n      <td>/paper/featureflow-robust-video-interpolation-...</td>\n      <td>0.422222</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kjksj\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
